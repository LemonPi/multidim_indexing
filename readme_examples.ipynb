{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4605630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "B = 256  # batch size (optional)\n",
    "shape = (B, 64, 64)\n",
    "high = torch.prod(torch.tensor(shape)).to(dtype=torch.long)\n",
    "data = torch.arange(0, high).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4702da15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(508276)\n"
     ]
    }
   ],
   "source": [
    "# index a single element\n",
    "print(data[124, 5, 52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d424ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    1,    2,  ...,   61,   62,   63],\n",
      "        [  64,   65,   66,  ...,  125,  126,  127],\n",
      "        [ 128,  129,  130,  ...,  189,  190,  191],\n",
      "        ...,\n",
      "        [3904, 3905, 3906,  ..., 3965, 3966, 3967],\n",
      "        [3968, 3969, 3970,  ..., 4029, 4030, 4031],\n",
      "        [4032, 4033, 4034,  ..., 4093, 4094, 4095]])\n",
      "tensor([[   0,    1,    2,  ...,   61,   62,   63],\n",
      "        [  64,   65,   66,  ...,  125,  126,  127],\n",
      "        [ 128,  129,  130,  ...,  189,  190,  191],\n",
      "        ...,\n",
      "        [3904, 3905, 3906,  ..., 3965, 3966, 3967],\n",
      "        [3968, 3969, 3970,  ..., 4029, 4030, 4031],\n",
      "        [4032, 4033, 4034,  ..., 4093, 4094, 4095]])\n",
      "tensor([[   0,    1,    2,  ...,   61,   62,   63],\n",
      "        [  64,   65,   66,  ...,  125,  126,  127],\n",
      "        [ 128,  129,  130,  ...,  189,  190,  191],\n",
      "        ...,\n",
      "        [3904, 3905, 3906,  ..., 3965, 3966, 3967],\n",
      "        [3968, 3969, 3970,  ..., 4029, 4030, 4031],\n",
      "        [4032, 4033, 4034,  ..., 4093, 4094, 4095]])\n"
     ]
    }
   ],
   "source": [
    "# index all dimensions given the first is index 0 (the following are equivalent)\n",
    "print(data[0])\n",
    "print(data[0, :, :])\n",
    "print(data[0, ...]) # pytorch only syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e80595e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[      5,      69,     133,  ...,    3909,    3973,    4037],\n",
      "        [   4101,    4165,    4229,  ...,    8005,    8069,    8133],\n",
      "        [   8197,    8261,    8325,  ...,   12101,   12165,   12229],\n",
      "        ...,\n",
      "        [1036293, 1036357, 1036421,  ..., 1040197, 1040261, 1040325],\n",
      "        [1040389, 1040453, 1040517,  ..., 1044293, 1044357, 1044421],\n",
      "        [1044485, 1044549, 1044613,  ..., 1048389, 1048453, 1048517]])\n",
      "tensor([[      5,      69,     133,  ...,    3909,    3973,    4037],\n",
      "        [   4101,    4165,    4229,  ...,    8005,    8069,    8133],\n",
      "        [   8197,    8261,    8325,  ...,   12101,   12165,   12229],\n",
      "        ...,\n",
      "        [1036293, 1036357, 1036421,  ..., 1040197, 1040261, 1040325],\n",
      "        [1040389, 1040453, 1040517,  ..., 1044293, 1044357, 1044421],\n",
      "        [1044485, 1044549, 1044613,  ..., 1048389, 1048453, 1048517]])\n"
     ]
    }
   ],
   "source": [
    "# index all dimensions given the last is index 5 (the following are equivalent)\n",
    "print(data[..., 5])\n",
    "print(data[:, :, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e90394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 64, 64])\n",
      "torch.Size([6, 64, 64])\n",
      "torch.Size([6, 64, 64])\n",
      "torch.Size([256, 6, 64])\n",
      "torch.Size([256, 6, 64])\n"
     ]
    }
   ],
   "source": [
    "idx = [4, 8, 15, 16, 23, 42]\n",
    "\n",
    "# index all dimensions given the first follows idx\n",
    "print(data[idx].shape) # (len(idx), 64, 64)\n",
    "print(data[idx, ...].shape)\n",
    "print(data[idx, :, :].shape)\n",
    "\n",
    "# index all dimensions given the second follows idx\n",
    "print(data[:, idx].shape)\n",
    "print(data[:, idx, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08401900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 64])\n"
     ]
    }
   ],
   "source": [
    "idx = [4, 8, 15, 16, 23, 42]\n",
    "idx2 = [5, 2, 7, 1, 32, 4]\n",
    "\n",
    "# index the last dimension when the first two are (4,5), (8,2), (15,7), (16,1), (23,32), and (42,4)\n",
    "print(data[idx, idx2].shape)  # (len(idx), 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0fe6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of 5 entries\n",
    "idx3 = [[0, 5, 3],\n",
    "        [2, 7, 5],\n",
    "        [100, 23, 45],\n",
    "        [3, 6, 4],\n",
    "        [4, 2, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd5deb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx3\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 3"
     ]
    }
   ],
   "source": [
    "print(data[idx3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8dad1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   323,   8645, 411117,  12676,  16513])\n",
      "tensor([   323,   8645, 411117,  12676,  16513])\n"
     ]
    }
   ],
   "source": [
    "# easier to convert it to something that allows column indexing first\n",
    "idx4 = torch.tensor(idx3)\n",
    "print(data[idx4[:,0], idx4[:,1], idx4[:,2]]) # returns the 5 entries as desired\n",
    "print(data[torch.unbind(idx4, -1)])  # can also use unbind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7231ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multidim_indexing import torch_view as view\n",
    "\n",
    "# simple wrapper with bounds checking\n",
    "data_multi = view.TorchMultidimView(data)\n",
    "# another view into the data, treating it as a batch of 2 dimensional grid data with X in [-5, 5] and Y in [0, 10]\n",
    "# can specify value to assign a query if it's out of bounds (defaults to -1)\n",
    "# note that the invalid value needs to be of the same type as the source, so we can't for example use float('inf') here\n",
    "data_batch = view.TorchMultidimView(data, value_ranges=[[0, B], [-5, 5], [0, 10]], invalid_value=-1)\n",
    "# another view into the data, treating it as a 3D grid data with X in [-2.5, 5], Y in [0, 4], and Z in [0, 10]\n",
    "data_3d = view.TorchMultidimView(data, value_ranges=[[-2.5, 5], [0, 4], [0, 10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2cfe7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   323,   8645, 411117,  12676,  16513])\n"
     ]
    }
   ],
   "source": [
    "# convert index to the corresponding type (pytorch vs numpy)\n",
    "key = torch.tensor(idx3, dtype=torch.long)\n",
    "print(data_multi[key]) # returns the 5 entries as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5328eb51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 4, 1])\n",
      "torch.Size([256, 4, 3])\n",
      "tensor([[[ 0.0000, -3.5000,  0.2000],\n",
      "         [ 0.0000, -4.0000,  0.1000],\n",
      "         [ 0.0000, -7.0000,  0.5000],\n",
      "         [ 0.0000,  3.0000,  2.0000]],\n",
      "\n",
      "        [[ 1.0000, -3.5000,  0.2000],\n",
      "         [ 1.0000, -4.0000,  0.1000],\n",
      "         [ 1.0000, -7.0000,  0.5000],\n",
      "         [ 1.0000,  3.0000,  2.0000]],\n",
      "\n",
      "        [[ 2.0000, -3.5000,  0.2000],\n",
      "         [ 2.0000, -4.0000,  0.1000],\n",
      "         [ 2.0000, -7.0000,  0.5000],\n",
      "         [ 2.0000,  3.0000,  2.0000]],\n",
      "\n",
      "        [[ 3.0000, -3.5000,  0.2000],\n",
      "         [ 3.0000, -4.0000,  0.1000],\n",
      "         [ 3.0000, -7.0000,  0.5000],\n",
      "         [ 3.0000,  3.0000,  2.0000]]])\n",
      "tensor([[[48.0000, -3.5000,  0.2000],\n",
      "         [48.0000, -4.0000,  0.1000],\n",
      "         [48.0000, -7.0000,  0.5000],\n",
      "         [48.0000,  3.0000,  2.0000]],\n",
      "\n",
      "        [[49.0000, -3.5000,  0.2000],\n",
      "         [49.0000, -4.0000,  0.1000],\n",
      "         [49.0000, -7.0000,  0.5000],\n",
      "         [49.0000,  3.0000,  2.0000]],\n",
      "\n",
      "        [[50.0000, -3.5000,  0.2000],\n",
      "         [50.0000, -4.0000,  0.1000],\n",
      "         [50.0000, -7.0000,  0.5000],\n",
      "         [50.0000,  3.0000,  2.0000]],\n",
      "\n",
      "        [[51.0000, -3.5000,  0.2000],\n",
      "         [51.0000, -4.0000,  0.1000],\n",
      "         [51.0000, -7.0000,  0.5000],\n",
      "         [51.0000,  3.0000,  2.0000]]])\n",
      "tensor([[    577,     385,      -1,    3213],\n",
      "        [   4673,    4481,      -1,    7309],\n",
      "        [   8769,    8577,      -1,   11405],\n",
      "        ...,\n",
      "        [1032769, 1032577,      -1, 1035405],\n",
      "        [1036865, 1036673,      -1, 1039501],\n",
      "        [1040961, 1040769,      -1, 1043597]])\n",
      "tensor([[    577,     385,      -1,    3213],\n",
      "        [   4673,    4481,      -1,    7309],\n",
      "        [   8769,    8577,      -1,   11405],\n",
      "        ...,\n",
      "        [1032769, 1032577,      -1, 1035405],\n",
      "        [1036865, 1036673,      -1, 1039501],\n",
      "        [1040961, 1040769,      -1, 1043597]])\n"
     ]
    }
   ],
   "source": [
    "# query the other views using grid values\n",
    "# first, let's try keying the same 2D values across all batches\n",
    "value_key_per_batch = torch.tensor([[-3.5, 0.2],\n",
    "                                    [-4, 0.1],\n",
    "                                    [-7, 0.5],  # this is out of bounds\n",
    "                                    [3, 2]])\n",
    "# number of entries to query\n",
    "N = value_key_per_batch.shape[0]\n",
    "print(torch.arange(B, dtype=value_key_per_batch.dtype).reshape(B, 1, 1).repeat(1, N, 1).shape)\n",
    "# make the indices for all batches\n",
    "value_key_batch = torch.cat(\n",
    "    (torch.arange(B, dtype=value_key_per_batch.dtype).reshape(B, 1, 1).repeat(1, N, 1),\n",
    "     value_key_per_batch.repeat(B, 1, 1)), dim=-1)\n",
    "# keys can have an additional batch indices at the front\n",
    "print(value_key_batch.shape)  # (B, N, 3)\n",
    "# these 2 should be the same apart from the first batch index\n",
    "print(value_key_batch[0:N])\n",
    "print(value_key_batch[12*N:13*N])\n",
    "\n",
    "# should see some -1 to indicate invalid value\n",
    "print(data_batch[value_key_batch]) \n",
    "\n",
    "# also there is a shorthand for directly using the per batch indices\n",
    "print(data_batch[value_key_per_batch.repeat(B,1,1)]) # should be the same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fe533cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([      0,      -1, 1048575])\n",
      "tensor(1048575)\n",
      "tensor(1048576)\n"
     ]
    }
   ],
   "source": [
    "value_key_3d = torch.tensor([[-2.5, 0., 0.],  # right on the boundary of validity\n",
    "                             [-2.51, 0.5, 0], # out of bounds\n",
    "                             [5, 4, 10] # right on the boundary\n",
    "                            ]  \n",
    "                        )\n",
    "print(data_3d[value_key_3d]) # (0, -1 for invalid, high - 1)\n",
    "print(torch.prod(torch.tensor(data.shape)) - 1)\n",
    "print(high - 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_conda",
   "language": "python",
   "name": "dev_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
